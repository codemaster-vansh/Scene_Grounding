{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "aXfmcEhOftRl"
      },
      "id": "aXfmcEhOftRl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "y_XKhf1zf113"
      },
      "id": "y_XKhf1zf113",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ba2cad6a",
      "metadata": {
        "id": "ba2cad6a"
      },
      "source": [
        "# Visualising Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc5b149",
      "metadata": {
        "id": "9dc5b149"
      },
      "source": [
        "### 1. Imports and Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "78449bdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78449bdd",
        "outputId": "22978fbe-7a06-4096-e361-76fd9637ae0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from utils import FinalModel, visualize_prediction\n",
        "from config_io import save_to_config, get_config_value\n",
        "from transformers import RobertaModel, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\",add_prefix_space=True)\n",
        "text_encoder = RobertaModel.from_pretrained(\"roberta-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2b4190c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2b4190c2",
        "outputId": "842061c1-64b4-4f51-fb42-510d7e84aaa9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not NoneType",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3623014464.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_save_weight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel_save_weight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_config_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CHECKPOINTS_PATH\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Please provide the link for the {choices[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindowsPath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPosixPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m             raise NotImplementedError(\"cannot instantiate %r on your system\"\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# right flavour.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mparts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                     \u001b[0;31m# Force-cast str subclasses to str (issue #21127)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "choices = [\"final_weights.pth\",\"best_weights.pth\"]      #Choose\n",
        "i = 1\n",
        "\n",
        "model_save_weight_path = None\n",
        "\n",
        "ckpt_dir  = Path(get_config_value(\"CHECKPOINTS_PATH\", default=\"not-set\"))\n",
        "candidate = ckpt_dir / choices[i]\n",
        "\n",
        "if not candidate.is_file():                    # ‚Üê real existence test\n",
        "    print(f\"Please provide the link for {choices[i]}\")\n",
        "    model_save_weight_path = Path(\"/content/drive/MyDrive/refcoco_project/Weights_Checkpoint/best_weights.pth\")\n",
        "    save_to_config({\"CHECKPOINTS_PATH\": str(model_save_weight_path.parent)})\n",
        "else:\n",
        "    model_save_weight_path = candidate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Weight file:\", model_save_weight_path)"
      ],
      "metadata": {
        "id": "40jX5j8cg9ZD"
      },
      "id": "40jX5j8cg9ZD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba2859df",
      "metadata": {
        "id": "ba2859df"
      },
      "outputs": [],
      "source": [
        "model = FinalModel(textbackbone=text_encoder)\n",
        "state_dict = torch.load(model_save_weight_path)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2740fa4d",
      "metadata": {
        "id": "2740fa4d"
      },
      "source": [
        "## 3. Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64bb4ed0",
      "metadata": {
        "id": "64bb4ed0"
      },
      "outputs": [],
      "source": [
        "phrase = \"\"\n",
        "img_path : Path = Path(get_config_value(\"OUT_DIR\",default=\"not-set\")) / \"\"      #Fill with your folder first and then your"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f56033",
      "metadata": {
        "id": "a0f56033"
      },
      "outputs": [],
      "source": [
        "#Run this cell to see the image before predicted boxes\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "img_np = np.array(img)\n",
        "plt.imshow(img_np)\n",
        "plt.axis('off')\n",
        "plt.title(\"The image\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f1ac941",
      "metadata": {
        "id": "5f1ac941"
      },
      "outputs": [],
      "source": [
        "visualize_prediction(model,img_path,phrase,tokenizer,device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
<<<<<<< HEAD
  {
   "cell_type": "markdown",
   "id": "9dc5b149",
   "metadata": {},
   "source": [
    "### 1. Imports and Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78449bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from utils import FinalModel, visualize_prediction\n",
    "from config_io import save_to_config, get_config_value\n",
    "from transformers import RobertaModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\",add_prefix_space=True)\n",
    "text_encoder = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4190c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "choices = [\"final_weights.pth\",\"best_weights.pth\"]      #Choose\n",
    "i = 0\n",
    "model_save_weight_path = None\n",
    "ckpt_dir  = Path(get_config_value(\"CHECKPOINTS_PATH\", default=\"not-set\"))\n",
    "candidate = ckpt_dir / choices[i]\n",
    "\n",
    "if not candidate.is_file():                    # ‚Üê real existence test\n",
    "    print(f\"Please provide the link for {choices[i]}\")\n",
    "    model_save_weight_path = Path(\"/content/drive/MyDrive/refcoco_project/Weights_Checkpoint/best_weights.pth\")\n",
    "    save_to_config({\"CHECKPOINTS_PATH\": str(model_save_weight_path.parent)})\n",
    "else:\n",
    "    model_save_weight_path = candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2859df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalModel()\n",
    "state_dict = torch.load(model_save_weight_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2740fa4d",
   "metadata": {},
   "source": [
    "## 3. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"\"\n",
    "filename = \"\"\n",
    "\n",
    "\n",
    "base_dir      = Path(get_config_value(\"OUT_DIR\", default=\"not-set\"))\n",
    "img_path      = base_dir / filename\n",
    "\n",
    "if not img_path.is_file():\n",
    "    new_dir = Path(\n",
    "        input(\n",
    "            f\"File '{img_path}' not found.\\n\"\n",
    "            f\"Enter the directory that contains '{filename}': \"\n",
    "        ).strip()\n",
    "    ).expanduser().resolve()\n",
    "\n",
    "    # sanity-check the new directory\n",
    "    if not new_dir.is_dir():\n",
    "        raise FileNotFoundError(f\"‚Äò{new_dir}‚Äô is not a directory.\")\n",
    "    \n",
    "    save_to_config({\"TEST_IMG_DIR\": str(new_dir)})\n",
    "    \n",
    "    img_path = new_dir / filename\n",
    "    if not img_path.is_file():\n",
    "        raise FileNotFoundError(f\"‚Äò{img_path}‚Äô still does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f56033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell to see the image before predicted boxes\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img_np = np.array(img)\n",
    "plt.imshow(img_np)\n",
    "plt.axis('off')\n",
    "plt.title(\"The image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ac941",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_prediction(model,img_path,phrase,tokenizer,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
  "nbformat": 4,
  "nbformat_minor": 5
}
>>>>>>> ef6723fe1194ba04c7222b1234aa56f09a9395b4
