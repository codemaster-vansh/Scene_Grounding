{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "oxwN0f6e3_vo",
      "metadata": {
        "id": "oxwN0f6e3_vo"
      },
      "source": [
        "# Scene Grounding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gqwOTqwo4ENM",
      "metadata": {
        "id": "gqwOTqwo4ENM"
      },
      "source": [
        "## 1. Importing and Instantiations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Fk1qHlI12gSX",
      "metadata": {
        "id": "Fk1qHlI12gSX"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision transformers Pillow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc0a0b2f",
      "metadata": {
        "id": "cc0a0b2f"
      },
      "outputs": [],
      "source": [
        "# Run this cell if on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e406ad62",
      "metadata": {},
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "267932ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from pathlib import Path\n",
        "\n",
        "from transformers import AutoTokenizer, RobertaModel\n",
        "\n",
        "from scripts.utils import RefCOCODataset, FinalModel, box_loss, contrastive_loss, generalized_iou"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96c2c5b",
      "metadata": {},
      "source": [
        "Version Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W7Bai1M319VX",
      "metadata": {
        "id": "W7Bai1M319VX"
      },
      "outputs": [],
      "source": [
        "print(\"torch :\", torch.__version__)\n",
        "print(\"torchvision :\", torchvision.__version__)\n",
        "print(\"torchvision file :\", Path(torchvision.__file__).resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3525795",
      "metadata": {},
      "source": [
        "Instantiate Text Encoder and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c603df64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c603df64",
        "outputId": "f4781db0-a311-4280-90e5-7d5c0d6c48a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\",add_prefix_space=True)\n",
        "text_encoder = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "for param in text_encoder.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e212a9",
      "metadata": {},
      "source": [
        "## 2. Processing Begins"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b99a169",
      "metadata": {},
      "source": [
        "Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2108b1c7",
      "metadata": {
        "id": "2108b1c7"
      },
      "outputs": [],
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE  = 16\n",
        "EPOCHS      = 20\n",
        "LR          = 1e-4\n",
        "ALPHA_CTR   = 0.1          # weight for contrastive term\n",
        "MARGIN_CTR  = 0.2\n",
        "PATIENCE    = 3            # epochs to wait before LR drop\n",
        "FACTOR      = 0.5          # LR multiplier on plateau\n",
        "CLIP_NORM   = 1.0\n",
        "\n",
        "DATA_DIR = Path(\"\")         ## Change to your dataset directory, if y \n",
        "CHECKPOINT_PATH : Path # You are free to edit this.\n",
        "os.makedirs(CHECKPOINT_PATH,exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc20cfc",
      "metadata": {},
      "source": [
        "Instantiating Datasets and Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b95cc7",
      "metadata": {
        "id": "64b95cc7"
      },
      "outputs": [],
      "source": [
        "train_set = RefCOCODataset(DATA_DIR,\"train\",tokenizer)\n",
        "val_set = RefCOCODataset(DATA_DIR,\"val\",tokenizer)\n",
        "test_set = RefCOCODataset(DATA_DIR,\"test\",tokenizer)\n",
        "\n",
        "train_load = DataLoader(train_set,BATCH_SIZE,shuffle=True,pin_memory=True)\n",
        "val_load = DataLoader(val_set,BATCH_SIZE,shuffle=True,pin_memory=True)\n",
        "test_load = DataLoader(test_set, BATCH_SIZE, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4c7a4b",
      "metadata": {},
      "source": [
        "Instantiating Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e9de75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99e9de75",
        "outputId": "7aba67b0-91ac-4eaa-be1f-7f09f2b2d93b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-757642875.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ],
      "source": [
        "model = FinalModel(textbackbone=text_encoder).to(DEVICE)\n",
        "\n",
        "# lower LR for backbone, normal LR for the rest\n",
        "param_groups = [\n",
        "    {\"params\": model.backbone.parameters(), \"lr\": 0.25*LR},\n",
        "    {\"params\": [p for n,p in model.named_parameters() if \"backbone\" not in n],\n",
        "     \"lr\": LR}\n",
        "]\n",
        "optim     = torch.optim.AdamW(param_groups, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optim, mode=\"min\", factor=FACTOR, patience=PATIENCE, verbose=True)\n",
        "\n",
        "scaler = torch.amp.GradScaler(device=DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9518744",
      "metadata": {},
      "source": [
        "## 3. Training Begins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c05e5d87",
      "metadata": {
        "id": "c05e5d87"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    running = 0.\n",
        "    for batch in train_load:\n",
        "        imgs   = batch[\"image\"].to(DEVICE)\n",
        "        gt_box = batch[\"bbox\"].to(DEVICE)                 # (B,4)\n",
        "        toks   = {k:v.to(DEVICE) for k,v in batch[\"tokens\"].items()}\n",
        "\n",
        "        optim.zero_grad(set_to_none=True)\n",
        "        with torch.autocast(device_type=DEVICE):\n",
        "            pred_box, dec_out, img_tokens = model(imgs, toks)\n",
        "            loss_bbox = box_loss(pred_box, gt_box)\n",
        "            loss_ctr  = contrastive_loss(dec_out, img_tokens,\n",
        "                                               margin=MARGIN_CTR)\n",
        "            loss = loss_bbox + ALPHA_CTR*loss_ctr\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optim)                                  # for clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n",
        "        scaler.step(optim)\n",
        "        scaler.update()\n",
        "\n",
        "        running += loss.item() * imgs.size(0)\n",
        "    return running / len(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3264e5",
      "metadata": {
        "id": "9a3264e5"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    giou_best, l1_best = [], []\n",
        "    for batch in loader:\n",
        "        imgs  = batch[\"image\"].to(DEVICE)\n",
        "        gt    = batch[\"bbox\"].to(DEVICE).unsqueeze(1)      # (B,1,4)\n",
        "        toks  = {k:v.to(DEVICE) for k,v in batch[\"tokens\"].items()}\n",
        "\n",
        "        pred, _, _ = model(imgs, toks)\n",
        "\n",
        "        giou = 1. - generalized_iou(pred, gt).squeeze(-1)   # (B,Q)\n",
        "        l1   = F.l1_loss(pred, gt.expand_as(pred), reduction=\"none\").sum(-1)\n",
        "\n",
        "        giou_best.append(giou.max(1).values)\n",
        "        l1_best.append(l1.min(1).values)\n",
        "\n",
        "    giou_best = torch.cat(giou_best).mean().item()\n",
        "    l1_best   = torch.cat(l1_best).mean().item()\n",
        "    return giou_best, l1_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49a760e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49a760e3",
        "outputId": "9e613838-026d-4aab-d719-786787ea402e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 │ train L 1.4163 │ val mIoU 0.792 │ val L1 0.528 │ LR 1.00e-04\n",
            "Epoch 02 │ train L 1.2094 │ val mIoU 0.783 │ val L1 0.511 │ LR 1.00e-04\n",
            "Epoch 03 │ train L 1.1308 │ val mIoU 0.749 │ val L1 0.520 │ LR 1.00e-04\n",
            "Epoch 04 │ train L 1.0702 │ val mIoU 0.753 │ val L1 0.487 │ LR 1.00e-04\n",
            "Epoch 05 │ train L 1.0234 │ val mIoU 0.744 │ val L1 0.483 │ LR 1.00e-04\n",
            "Epoch 06 │ train L 0.9841 │ val mIoU 0.745 │ val L1 0.495 │ LR 1.00e-04\n",
            "Epoch 07 │ train L 0.9449 │ val mIoU 0.727 │ val L1 0.486 │ LR 1.00e-04\n",
            "Epoch 08 │ train L 0.9114 │ val mIoU 0.749 │ val L1 0.487 │ LR 1.00e-04\n",
            "Epoch 09 │ train L 0.8815 │ val mIoU 0.713 │ val L1 0.464 │ LR 1.00e-04\n",
            "Epoch 10 │ train L 0.8641 │ val mIoU 0.725 │ val L1 0.477 │ LR 1.00e-04\n",
            "Epoch 11 │ train L 0.8345 │ val mIoU 0.726 │ val L1 0.466 │ LR 1.00e-04\n",
            "Epoch 12 │ train L 0.8155 │ val mIoU 0.718 │ val L1 0.457 │ LR 1.00e-04\n",
            "Epoch 13 │ train L 0.7967 │ val mIoU 0.732 │ val L1 0.477 │ LR 1.00e-04\n",
            "Epoch 14 │ train L 0.7779 │ val mIoU 0.715 │ val L1 0.476 │ LR 1.00e-04\n",
            "Epoch 15 │ train L 0.7555 │ val mIoU 0.713 │ val L1 0.467 │ LR 1.00e-04\n",
            "Epoch 16 │ train L 0.7427 │ val mIoU 0.714 │ val L1 0.457 │ LR 1.00e-04\n",
            "Epoch 17 │ train L 0.7198 │ val mIoU 0.717 │ val L1 0.466 │ LR 1.00e-04\n",
            "Epoch 18 │ train L 0.7133 │ val mIoU 0.720 │ val L1 0.460 │ LR 1.00e-04\n",
            "Epoch 19 │ train L 0.6968 │ val mIoU 0.715 │ val L1 0.450 │ LR 1.00e-04\n",
            "Epoch 20 │ train L 0.6816 │ val mIoU 0.716 │ val L1 0.456 │ LR 1.00e-04\n"
          ]
        }
      ],
      "source": [
        "best_val = float(\"inf\")\n",
        "\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    train_loss = train_one_epoch()\n",
        "    val_giou, val_l1 = evaluate(val_load)\n",
        "    val_metric = val_giou + val_l1            # scheduler uses this\n",
        "\n",
        "    scheduler.step(val_metric)                # ReduceLRonPlateau\n",
        "\n",
        "    lr_now = optim.param_groups[1][\"lr\"]\n",
        "    print(f\"Epoch {ep:02d} │ train L {train_loss:.4f} │ \"\n",
        "          f\"val mIoU {val_giou:.3f} │ val L1 {val_l1:.3f} │ \"\n",
        "          f\"LR {lr_now:.2e}\")\n",
        "    \n",
        "    checkpoint = {\n",
        "        \"epoch\":ep,\n",
        "        \"model_state_dict\":model.state_dict()\n",
        "    }\n",
        "\n",
        "    torch.save(checkpoint, CHECKPOINT_PATH / \"final_weights.pth\")\n",
        "\n",
        "    if val_metric < best_val:\n",
        "        best_val = val_metric\n",
        "        torch.save(checkpoint,CHECKPOINT_PATH/\"best_weights.pth\")\n",
        "        print(f\"New best validation metric: {best_val:.4f} - saved to best_weights.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b007b78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b007b78",
        "outputId": "032ac117-9722-407b-ee41-33598f0f9503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "──────── TEST REPORT ────────\n",
            "mIoU  (best query) : 0.700\n",
            "Mean L1 (cxcywh)   : 0.445\n",
            "─────────────────────────────\n"
          ]
        }
      ],
      "source": [
        "test_giou, test_l1 = evaluate(test_load)\n",
        "print(\"\\n──────── TEST REPORT ────────\")\n",
        "print(f\"mIoU  (best query) : {test_giou:.3f}\")\n",
        "print(f\"Mean L1 (cxcywh)   : {test_l1:.3f}\")\n",
        "print(\"─────────────────────────────\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
